{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23f2cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating video for 71 frames...\n",
      "✅ Skeleton video saved to: skeleton_check.mp4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "FILE_PATH = \"../training_dataset/sequences/NSL_Consonant_Multi/S3_NSL_Consonant_Prepared/S3_all_consonant_Phone_Camera/BA_2507_2577.npz\"\n",
    "OUTPUT_VIDEO = \"skeleton_check.mp4\"\n",
    "WIDTH, HEIGHT = 800, 800\n",
    "FPS = 60\n",
    "\n",
    "# MediaPipe Connection Maps\n",
    "HAND_CONNECTIONS = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),      # Thumb\n",
    "    (0, 5), (5, 6), (6, 7), (7, 8),      # Index\n",
    "    (5, 9), (9, 10), (10, 11), (11, 12), # Middle\n",
    "    (9, 13), (13, 14), (14, 15), (15, 16), # Ring\n",
    "    (13, 17), (0, 17), (17, 18), (18, 19), (19, 20) # Pinky\n",
    "]\n",
    "\n",
    "POSE_CONNECTIONS = [\n",
    "    (11, 12), (11, 13), (13, 15), # Left arm\n",
    "    (12, 14), (14, 16),           # Right arm\n",
    "    (11, 23), (12, 24), (23, 24)  # Torso\n",
    "]\n",
    "\n",
    "def draw_skeleton(data_path, output_path):\n",
    "    # Load the npz file\n",
    "    data = np.load(data_path)\n",
    "    pose = data['pose']  # (Frames, 33, 4)\n",
    "    lh = data['lh']      # (Frames, 21, 3)\n",
    "    rh = data['rh']      # (Frames, 21, 3)\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, FPS, (WIDTH, HEIGHT))\n",
    "\n",
    "    print(f\"Generating video for {len(pose)} frames...\")\n",
    "\n",
    "    for i in range(len(pose)):\n",
    "        # Create black canvas\n",
    "        frame = np.zeros((HEIGHT, WIDTH, 3), dtype=np.uint8)\n",
    "\n",
    "        # 1. DRAW HANDS (Wrist-Centric)\n",
    "        # Since they are normalized around 0,0, we move them to centers\n",
    "        # and scale them up for visibility\n",
    "        lw_pose = pose[i][15] \n",
    "        rw_pose = pose[i][16]\n",
    "\n",
    "        # Define centers based on actual Pose landmarks\n",
    "        # If Pose exists, we attach hand to wrist. If not (Cropped), we use a default center.\n",
    "        if not np.all(lw_pose[:2] == 0):\n",
    "            l_center = (int(lw_pose[0] * WIDTH), int(lw_pose[1] * HEIGHT))\n",
    "        else:\n",
    "            l_center = (200, 400) # Default for cropped\n",
    "\n",
    "        if not np.all(rw_pose[:2] == 0):\n",
    "            r_center = (int(rw_pose[0] * WIDTH), int(rw_pose[1] * HEIGHT))\n",
    "        else:\n",
    "            r_center = (600, 400) # Default for cropped\n",
    "\n",
    "        # Now apply this center to the drawing logic\n",
    "        centers = {'left': l_center, 'right': r_center}\n",
    "        # IMPORTANT: Since Pose and Hand are in different scales now, \n",
    "        # you might need to adjust this scale factor to match the body size\n",
    "        hand_visual_scale = 200\n",
    "\n",
    "        for side, hand_pts, color in [('left', lh[i], (255, 0, 0)), ('right', rh[i], (0, 0, 255))]:\n",
    "            if np.all(hand_pts == 0): continue\n",
    "            \n",
    "            current_center = centers[side]\n",
    "            \n",
    "            for start, end in HAND_CONNECTIONS:\n",
    "                # We add the normalized finger points to the actual wrist center\n",
    "                p1 = (int(hand_pts[start][0] * hand_visual_scale + current_center[0]), \n",
    "                    int(hand_pts[start][1] * hand_visual_scale + current_center[1]))\n",
    "                p2 = (int(hand_pts[end][0] * hand_visual_scale + current_center[0]), \n",
    "                    int(hand_pts[end][1] * hand_visual_scale + current_center[1]))\n",
    "                cv2.line(frame, p1, p2, color, 2)\n",
    "\n",
    "            # Draw points\n",
    "            for pt in hand_pts:\n",
    "                px = int(pt[0] * hand_visual_scale + centers[side][0])\n",
    "                py = int(pt[1] * hand_visual_scale + centers[side][1])\n",
    "                cv2.circle(frame, (px, py), 3, (255, 255, 255), -1)\n",
    "\n",
    "        # 2. DRAW POSE (Full View)\n",
    "        # Pose is in 0-1 range, we scale to full screen\n",
    "        for start, end in POSE_CONNECTIONS:\n",
    "            p1_raw = pose[i][start]\n",
    "            p2_raw = pose[i][end]\n",
    "            \n",
    "            # Only draw if visibility is decent\n",
    "            if p1_raw[3] > 0.5 and p2_raw[3] > 0.5:\n",
    "                p1 = (int(p1_raw[0] * WIDTH), int(p1_raw[1] * HEIGHT))\n",
    "                p2 = (int(p2_raw[0] * WIDTH), int(p2_raw[1] * HEIGHT))\n",
    "                cv2.line(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "        # Add Frame Info\n",
    "        cv2.putText(frame, f\"Frame: {i}\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"✅ Skeleton video saved to: {output_path}\")\n",
    "\n",
    "# Run the visualization\n",
    "draw_skeleton(FILE_PATH, OUTPUT_VIDEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bdb0063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted BA.npz to keypoints.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_enhanced_npz_to_json(npz_path, output_json_path, video_path_label=None):\n",
    "    \"\"\"\n",
    "    Converts enhanced NPZ files back to JSON.\n",
    "    Reconstructs original coordinates using: (normalized * scale) + wrist\n",
    "    \"\"\"\n",
    "    # 1. Load the NPZ data\n",
    "    data = np.load(npz_path)\n",
    "    \n",
    "    pose_array = data['pose']      # (Frames, 33, 4)\n",
    "    lh_array = data['lh']          # (Frames, 21, 3)\n",
    "    rh_array = data['rh']          # (Frames, 21, 3)\n",
    "    lh_meta = data['lh_meta']      # (Frames, 4) -> [wx, wy, wz, scale]\n",
    "    rh_meta = data['rh_meta']      # (Frames, 4) -> [wx, wy, wz, scale]\n",
    "    \n",
    "    # Extract video info [fps, width, height] saved in NPZ\n",
    "    # If video_info isn't there, we fallback to defaults\n",
    "    if 'video_info' in data:\n",
    "        fps_orig, width, height = data['video_info']\n",
    "    else:\n",
    "        fps_orig, width, height = 60.0, 1920, 1080\n",
    "\n",
    "    # The user specifically requested 'fps': 60 in the JSON\n",
    "    fps_to_use = 60 \n",
    "\n",
    "    # 2. Construct JSON Structure\n",
    "    output_data = {\n",
    "        'metadata': {\n",
    "            'video_path': str(video_path_label) if video_path_label else \"unknown\",\n",
    "            'fps': float(fps_to_use),\n",
    "            'frame_width': int(width),\n",
    "            'frame_height': int(height),\n",
    "            'total_frames': int(pose_array.shape[0]),\n",
    "            'frame_skip': 1,\n",
    "            'hands_swapped': True\n",
    "        },\n",
    "        'frames': []\n",
    "    }\n",
    "\n",
    "    # 3. Process Frames\n",
    "    for i in range(pose_array.shape[0]):\n",
    "        frame_data = {\n",
    "            'frame_number': i + 1,\n",
    "            'timestamp': i / fps_to_use,\n",
    "            'pose': None,\n",
    "            'hands': {'left': None, 'right': None},\n",
    "            'face': None\n",
    "        }\n",
    "\n",
    "        # --- Reconstruct Pose ---\n",
    "        if not np.all(pose_array[i] == 0):\n",
    "            frame_data['pose'] = [\n",
    "                {'x': float(lm[0]), 'y': float(lm[1]), 'z': float(lm[2]), 'visibility': float(lm[3])}\n",
    "                for lm in pose_array[i]\n",
    "            ]\n",
    "\n",
    "        # --- Reconstruct Left Hand ---\n",
    "        # Formula: (normalized_coords * scale) + wrist_position\n",
    "        if not np.all(lh_array[i] == 0):\n",
    "            wx, wy, wz, scale = lh_meta[i]\n",
    "            frame_data['hands']['left'] = [\n",
    "                {\n",
    "                    'x': float((lm[0] * scale) + wx),\n",
    "                    'y': float((lm[1] * scale) + wy),\n",
    "                    'z': float((lm[2] * scale) + wz)\n",
    "                }\n",
    "                for lm in lh_array[i]\n",
    "            ]\n",
    "\n",
    "        # --- Reconstruct Right Hand ---\n",
    "        if not np.all(rh_array[i] == 0):\n",
    "            wx, wy, wz, scale = rh_meta[i]\n",
    "            frame_data['hands']['right'] = [\n",
    "                {\n",
    "                    'x': float((lm[0] * scale) + wx),\n",
    "                    'y': float((lm[1] * scale) + wy),\n",
    "                    'z': float((lm[2] * scale) + wz)\n",
    "                }\n",
    "                for lm in rh_array[i]\n",
    "            ]\n",
    "\n",
    "        output_data['frames'].append(frame_data)\n",
    "\n",
    "    # 4. Save JSON\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Successfully converted {npz_path.name} to {output_json_path}\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "npz_file = Path(\"../training_dataset/sequences/NSL_CONSONANT_PART_1/S1_NSL_Consonant_Bright/BA.npz\")\n",
    "convert_enhanced_npz_to_json(npz_file, \"keypoints.json\", video_path_label=\"S1/A.MOV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbc231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
